{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecc2d4ba-7876-483b-acd9-f564c24bd897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:54.260681Z",
     "iopub.status.busy": "2024-05-07T19:47:54.260681Z",
     "iopub.status.idle": "2024-05-07T19:47:56.536431Z",
     "shell.execute_reply": "2024-05-07T19:47:56.536431Z",
     "shell.execute_reply.started": "2024-05-07T19:47:54.260681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import sys\n",
    "import os\n",
    "import git\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d777e66c-b8ce-4295-b6c0-0ac7bf5801db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.536431Z",
     "iopub.status.busy": "2024-05-07T19:47:56.536431Z",
     "iopub.status.idle": "2024-05-07T19:47:56.619744Z",
     "shell.execute_reply": "2024-05-07T19:47:56.619744Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.536431Z"
    }
   },
   "outputs": [],
   "source": [
    "git_repo = git.Repo(\".\", search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "sys.path.insert(0, os.path.join(git_root, 'src'))\n",
    "\n",
    "import utilities.helper\n",
    "import trodes.read_exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d1b186-21fe-466c-bfed-26e0f59d6e42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.619744Z",
     "iopub.status.busy": "2024-05-07T19:47:56.619744Z",
     "iopub.status.idle": "2024-05-07T19:47:56.633872Z",
     "shell.execute_reply": "2024-05-07T19:47:56.633872Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.619744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/short/Documents/GitHub/nose_poke_identifier'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a93c4e1-36d1-45fb-853e-ab57c28d6e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.633872Z",
     "iopub.status.busy": "2024-05-07T19:47:56.633872Z",
     "iopub.status.idle": "2024-05-07T19:47:56.646108Z",
     "shell.execute_reply": "2024-05-07T19:47:56.646108Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.633872Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_floats(s):\n",
    "    \"\"\"\n",
    "    Extracts all floats from a string and returns them as a list of strings.\n",
    "\n",
    "    Parameters:\n",
    "    - s (str): The string to extract floats from.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of strings, each representing a float found in the input string.\n",
    "    \"\"\"\n",
    "    float_pattern = r\"[-+]?\\d*\\.\\d+|\\d+\"\n",
    "    return [str(float(num)) for num in re.findall(float_pattern, s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e044c8-17c5-4516-a781-a9b21ca8e6e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.646108Z",
     "iopub.status.busy": "2024-05-07T19:47:56.646108Z",
     "iopub.status.idle": "2024-05-07T19:47:56.656712Z",
     "shell.execute_reply": "2024-05-07T19:47:56.656712Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.646108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path of the directory that contains the Spike Gadgets recording and the exported timestamp files\n",
    "# Exported with this tool https://docs.spikegadgets.com/en/latest/basic/ExportFunctions.html\n",
    "# Export these files:\n",
    "    # -raw – Continuous raw band export.\n",
    "    # -dio – Digital IO channel state change export.\n",
    "    # -analogio – Continuous analog IO export.\n",
    "INPUT_DIR = \"./data\"\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n",
    "TONE_DIN = \"dio_ECU_Din1\"\n",
    "TONE_STATE = 1\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_PREFIX = \"rce_pilot_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dac3d1f-76bd-41aa-8fa0-31a18c7cea20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.662231Z",
     "iopub.status.busy": "2024-05-07T19:47:56.662231Z",
     "iopub.status.idle": "2024-05-07T19:47:56.672065Z",
     "shell.execute_reply": "2024-05-07T19:47:56.672065Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.662231Z"
    }
   },
   "outputs": [],
   "source": [
    "COLS_TO_KEEP = ['session_dir', 'recording', 'metadata_dir', 'metadata_file', 'original_file', 'filename',\n",
    "                'session_path', 'all_subjects', 'current_subject', 'event_timestamps', 'video_name', \n",
    "                'video_timestamps', 'event_frames', 'first_item_data']\n",
    "\n",
    "RAW_COLS_TO_KEEP = ['session_dir', 'recording', 'original_file', 'session_path', 'current_subject', \n",
    "                    'first_item_data', 'first_timestamp', 'all_subjects']\n",
    "\n",
    "STATE_COLS_TO_KEEP = ['session_dir', 'metadata_file', 'event_timestamps', 'video_name', \n",
    "                      'video_timestamps', 'event_frames',]\n",
    "\n",
    "same_columns = ['session_dir', 'video_name']\n",
    "different_columns = ['metadata_file', 'event_frames', 'event_timestamps']\n",
    "\n",
    "# ALL_SESSION_DIR = glob.glob(\"/scratch/back_up/reward_competition_extention/data/standard/2023_06_*/*.rec\")\n",
    "ALL_SESSION_DIR = glob.glob(r\"./data/*.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f31255-9a8a-493b-93bf-55bd7dd42945",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.672065Z",
     "iopub.status.busy": "2024-05-07T19:47:56.672065Z",
     "iopub.status.idle": "2024-05-07T19:47:56.685596Z",
     "shell.execute_reply": "2024-05-07T19:47:56.685596Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.672065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_SESSION_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843624a8-378a-45e2-9a42-1ab3b204983d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.694120Z",
     "iopub.status.busy": "2024-05-07T19:47:56.694120Z",
     "iopub.status.idle": "2024-05-07T19:47:56.712167Z",
     "shell.execute_reply": "2024-05-07T19:47:56.712167Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.694120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Session: 20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Din1.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Din1.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Din2.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Din2.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Din3.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Din3.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Din4.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Din4.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Dout1.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Dout1.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Dout2.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Dout2.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Dout3.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Dout3.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Dout4.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.dio_ECU_Dout4.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.timestamps.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.raw\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.timestamps.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.timestamps.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.time\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.timestamps.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.timestampoffset.txt due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.timestampoffset\\\\20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.timestampoffset.txt'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Din1.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Din1.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Din2.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Din2.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Din3.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Din3.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Din4.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Din4.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Dout1.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Dout1.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Dout2.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Dout2.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Dout3.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Dout3.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Dout4.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.DIO\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.dio_ECU_Dout4.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.timestamps.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.raw\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.timestamps.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.timestamps.dat due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.time\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.timestamps.dat'\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.timestampoffset.txt due to error: [Errno 2] No such file or directory: './data\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.timestampoffset\\\\20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.timestampoffset.txt'\n"
     ]
    }
   ],
   "source": [
    "# Saving the trodes data for each session\n",
    "# Each key is a session name\n",
    "# Each value is a dictionary of every recording file in that session\n",
    "session_to_trodes_data = utilities.helper.create_recursive_dict()\n",
    "\n",
    "\n",
    "# Saving the path of the session recording\n",
    "session_to_path = {}\n",
    "\n",
    "# Going through each session recording\n",
    "# Which includes all the recordings from all the miniloggers and cameras\n",
    "for session_path in ALL_SESSION_DIR:   \n",
    "    try:\n",
    "        # Getting the name of the session from the path\n",
    "        session_basename = os.path.splitext(os.path.basename(session_path))[0]\n",
    "        print(\"Current Session: {}\".format(session_basename))\n",
    "        # Reading the trodes data for every recording file in the session directory\n",
    "        session_to_trodes_data[session_basename] = trodes.read_exported.organize_all_trodes_export(session_path)\n",
    "        \n",
    "        session_to_path[session_basename] = session_path\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6924e0ba-3d08-4a2d-84a2-28c8ad8c2e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.712167Z",
     "iopub.status.busy": "2024-05-07T19:47:56.712167Z",
     "iopub.status.idle": "2024-05-07T19:47:56.742206Z",
     "shell.execute_reply": "2024-05-07T19:47:56.740178Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.712167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Session: 20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1\n",
      "Current Video Name: 20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.1.videoTimeStamps.cameraHWSync\n",
      "Current Video Name: 20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.2.videoTimeStamps.cameraHWSync\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/short/Documents/GitHub/nose_poke_identifier\\src\\trodes\\read_exported.py:62: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return np.dtype(dtype_spec)\n"
     ]
    }
   ],
   "source": [
    "for session_path in ALL_SESSION_DIR:   \n",
    "    try:\n",
    "        session_basename = os.path.splitext(os.path.basename(session_path))[0]\n",
    "        print(\"Current Session: {}\".format(session_basename))\n",
    "        file_to_video_timestamps = {}\n",
    "        for video_timestamps in glob.glob(os.path.join(session_path, \"*cameraHWSync\")):\n",
    "            video_basename = os.path.basename(video_timestamps)\n",
    "            print(\"Current Video Name: {}\".format(video_basename))\n",
    "            timestamp_array = trodes.read_exported.read_trodes_extracted_data_file(video_timestamps)\n",
    "            if \"video_timestamps\" not in session_to_trodes_data[session_basename][session_basename]:\n",
    "                session_to_trodes_data[session_basename][session_basename][\"video_timestamps\"] = defaultdict(dict)\n",
    "            session_to_trodes_data[session_basename][session_basename][\"video_timestamps\"][video_basename.split(\".\")[-3]] = timestamp_array\n",
    "    \n",
    "    \n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "236db0da-8e5d-4d52-b517-6265c0d5bb03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.742206Z",
     "iopub.status.busy": "2024-05-07T19:47:56.742206Z",
     "iopub.status.idle": "2024-05-07T19:47:56.767004Z",
     "shell.execute_reply": "2024-05-07T19:47:56.767004Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.742206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe from the nested dictionary\n",
    "trodes_metadata_df = pd.DataFrame.from_dict({(i,j,k,l): session_to_trodes_data[i][j][k][l] \n",
    "                           for i in session_to_trodes_data.keys() \n",
    "                           for j in session_to_trodes_data[i].keys()\n",
    "                           for k in session_to_trodes_data[i][j].keys()\n",
    "                           for l in session_to_trodes_data[i][j][k].keys()},\n",
    "                           orient='index')\n",
    "\n",
    "# Resetting the index and renaming the columns\n",
    "trodes_metadata_df = trodes_metadata_df.reset_index()\n",
    "trodes_metadata_df = trodes_metadata_df.rename(columns={'level_0': 'session_dir', 'level_1': 'recording', 'level_2': 'metadata_dir', 'level_3': 'metadata_file'}, errors=\"ignore\")\n",
    "\n",
    "# Adding the session path to the dataframe\n",
    "trodes_metadata_df[\"session_path\"] = trodes_metadata_df[\"session_dir\"].map(session_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1958ff49-5262-487d-8e2c-e620f455b1fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.767004Z",
     "iopub.status.busy": "2024-05-07T19:47:56.767004Z",
     "iopub.status.idle": "2024-05-07T19:47:56.785537Z",
     "shell.execute_reply": "2024-05-07T19:47:56.785537Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.767004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the dtype name of each column in the numpy array\n",
    "trodes_metadata_df[\"first_dtype_name\"] = trodes_metadata_df[\"data\"].apply(lambda x: x.dtype.names[0])\n",
    "# Getting the first item of each column in the numpy array\n",
    "trodes_metadata_df[\"first_item_data\"] = trodes_metadata_df[\"data\"].apply(lambda x: x[x.dtype.names[0]])\n",
    "\n",
    "# Same as above but for the last column\n",
    "trodes_metadata_df[\"last_dtype_name\"] = trodes_metadata_df[\"data\"].apply(lambda x: x.dtype.names[-1])\n",
    "trodes_metadata_df[\"last_item_data\"] = trodes_metadata_df[\"data\"].apply(lambda x: x[x.dtype.names[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfec94ce-a0c2-4448-86e5-cbb291fa424b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.789552Z",
     "iopub.status.busy": "2024-05-07T19:47:56.789552Z",
     "iopub.status.idle": "2024-05-07T19:47:56.797705Z",
     "shell.execute_reply": "2024-05-07T19:47:56.797705Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.789552Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_by_multiple_delimiters(s, delimiters):\n",
    "    \"\"\"\n",
    "    Splits a string by multiple delimiters.\n",
    "\n",
    "    Parameters:\n",
    "    - s (str): The string to split.\n",
    "    - delimiters (list): A list of delimiters to split the string by.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of substrings.\n",
    "    \"\"\"\n",
    "    return re.split('|'.join(map(re.escape, delimiters)), s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b30f960e-b1e2-4fb2-a998-b6a74696eec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.797705Z",
     "iopub.status.busy": "2024-05-07T19:47:56.797705Z",
     "iopub.status.idle": "2024-05-07T19:47:56.814204Z",
     "shell.execute_reply": "2024-05-07T19:47:56.814204Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.797705Z"
    }
   },
   "outputs": [],
   "source": [
    "trodes_metadata_df[\"all_subjects\"] = trodes_metadata_df[\"session_dir\"].apply(lambda x: x.split(\"subj\")[-1].strip(\"_\").replace(\"-\", \".\"))#.split(\"t\")[0].strip(\"_\").replace(\"_\",\".\").split(\".and.\"))\n",
    "trodes_metadata_df[\"all_subjects\"] = trodes_metadata_df[\"all_subjects\"].apply(lambda x: sorted(extract_floats(x)))\n",
    "\n",
    "trodes_metadata_df[\"current_subject\"] = trodes_metadata_df[\"recording\"].apply(lambda x: x.split(\"subj\")[-1].strip(\"_\").replace(\"-\", \".\").replace(\"_\", \".\"))#.split(\"t\")[0].strip(\"_\").replace(\"_\",\".\").split(\".and.\"))\n",
    "trodes_metadata_df[\"current_subject\"] = trodes_metadata_df[\"current_subject\"].apply(lambda x: str(extract_floats(x)[0]).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83002fe5-6270-44c9-b57b-230e23c92f99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.814204Z",
     "iopub.status.busy": "2024-05-07T19:47:56.814204Z",
     "iopub.status.idle": "2024-05-07T19:47:56.836871Z",
     "shell.execute_reply": "2024-05-07T19:47:56.835852Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.814204Z"
    }
   },
   "outputs": [],
   "source": [
    "METADATA_TO_KEEP = ['raw', 'DIO', 'video_timestamps']\n",
    "\n",
    "trodes_metadata_df = trodes_metadata_df[trodes_metadata_df[\"metadata_dir\"].isin(METADATA_TO_KEEP)]\n",
    "trodes_metadata_df = trodes_metadata_df[~trodes_metadata_df[\"metadata_file\"].str.contains(\"out\")]\n",
    "trodes_metadata_df = trodes_metadata_df[~trodes_metadata_df[\"metadata_file\"].str.contains(\"coordinates\")]\n",
    "trodes_metadata_df = trodes_metadata_df.reset_index(drop=True)\n",
    "\n",
    "trodes_raw_df = trodes_metadata_df[(trodes_metadata_df[\"metadata_dir\"] == \"raw\") & (trodes_metadata_df[\"metadata_file\"] == \"timestamps\")].copy()\n",
    "trodes_raw_df[\"first_timestamp\"] = trodes_raw_df[\"first_item_data\"].apply(lambda x: x[0])\n",
    "recording_to_first_timestamp = trodes_raw_df.set_index('session_dir')['first_timestamp'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "566eb010-3eb7-403a-99d3-3a7ab7df58db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-07T19:47:56.836871Z",
     "iopub.status.busy": "2024-05-07T19:47:56.836871Z",
     "iopub.status.idle": "2024-05-07T19:47:56.860043Z",
     "shell.execute_reply": "2024-05-07T19:47:56.860043Z",
     "shell.execute_reply.started": "2024-05-07T19:47:56.836871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>clock rate</th>\n",
       "      <th>fields</th>\n",
       "      <th>data</th>\n",
       "      <th>filename</th>\n",
       "      <th>session_path</th>\n",
       "      <th>first_dtype_name</th>\n",
       "      <th>first_item_data</th>\n",
       "      <th>last_dtype_name</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>first_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [session_dir, recording, metadata_dir, metadata_file, clock rate, fields, data, filename, session_path, first_dtype_name, first_item_data, last_dtype_name, last_item_data, all_subjects, current_subject, first_timestamp]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trodes_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919dac1-a6da-4046-a8ea-7c58b0594913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
